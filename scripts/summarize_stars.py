import os
import time
import requests
import json
import concurrent.futures
from typing import Dict, List, Optional

# é…ç½®token
GITHUB_TOKEN = os.environ.get("STARRED_GITHUB_TOKEN")
OPENROUTER_API_KEY = os.environ.get("OPENROUTER_API_KEY")

# åŠ è½½é…ç½®æ–‡ä»¶
CONFIG_PATH = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'config.json')

def load_config():
    try:
        with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {'language': 'zh'}  # é»˜è®¤ä¸­æ–‡

config = load_config()

# ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
github_username = config.get("github_username")
github_token_env = config.get("github_token_env")
openrouter_api_key_env = config.get("openrouter_api_key_env")
model_choice = config.get("model_choice", "copilot")

default_copilot_model = config.get("default_copilot_model")
default_openrouter_model = config.get("default_openrouter_model")
max_workers = config.get("max_workers")
batch_size = config.get("batch_size")
request_timeout = config.get("request_timeout")
rate_limit_delay = config.get("rate_limit_delay")
request_retry_delay = config.get("request_retry_delay")
retry_attempts = config.get("retry_attempts")
readme_sum_path = config.get("readme_sum_path")

# ç¯å¢ƒå˜é‡åŠ è½½
GITHUB_USERNAME = github_username

# å°† copilot_summarize å’Œ openrouter_summarize å‡½æ•°ç§»åŠ¨åˆ° get_summarize_func ä¹‹å‰

def copilot_summarize(repo: Dict) -> Optional[str]:
    """ä½¿ç”¨ GitHub Copilot API è¿›è¡Œæ€»ç»“"""
    if not GITHUB_TOKEN:
        print("ç¼ºå°‘ STARRED_GITHUB_TOKENï¼Œæ— æ³•è°ƒç”¨ GitHub Copilot API")
        return None

    headers = {
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "Accept": "application/json",
        "X-GitHub-Api-Version": "2023-07-01",
        "Content-Type": "application/json"
    }
    data = {
        "model": os.environ.get("GITHUB_COPILOT_MODEL", DEFAULT_COPILOT_MODEL),
        "messages": [{"role": "user", "content": generate_prompt(repo)}],
        "max_tokens": 600,
        "temperature": 0.4
    }
    response = make_api_request(API_ENDPOINTS["copilot"], headers, data)
    if response:
        return response.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
    return None


def openrouter_summarize(repo: Dict) -> Optional[str]:
    """ä½¿ç”¨ OpenRouter API è¿›è¡Œæ€»ç»“"""
    if not OPENROUTER_API_KEY:
        print("ç¼ºå°‘ OPENROUTER_API_KEYï¼Œæ— æ³•è°ƒç”¨ OpenRouter API")
        return None

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {
        "model": DEFAULT_OPENROUTER_MODEL,
        "messages": [{"role": "user", "content": generate_prompt(repo)}]
    }
    response = make_api_request(API_ENDPOINTS["openrouter"], headers, data)
    if response:
        return response.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
    return None

# æ ¹æ®é…ç½®é€‰æ‹©æ€»ç»“å‡½æ•°
def get_summarize_func():
    if model_choice == 'copilot':
        return copilot_summarize
    elif model_choice == 'openrouter':
        return openrouter_summarize
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹é€‰æ‹©: {model_choice}")

summarize_func = get_summarize_func()

# API é…ç½®
DEFAULT_COPILOT_MODEL = default_copilot_model
DEFAULT_OPENROUTER_MODEL = default_openrouter_model
MAX_WORKERS = max_workers
BATCH_SIZE = batch_size
REQUEST_TIMEOUT = request_timeout
RATE_LIMIT_DELAY = rate_limit_delay
REQUEST_RETRY_DELAY = request_retry_delay
RETRY_ATTEMPTS = retry_attempts

# è¾“å‡ºé…ç½®
README_SUM_PATH = readme_sum_path
LANGUAGE = config.get('language', 'zh')

# æ‰“å° API Key å‰ç¼€ç”¨äºè°ƒè¯•
if OPENROUTER_API_KEY:
    print(f"OpenRouter API Key å‰ç¼€: {OPENROUTER_API_KEY[:6]}...")
if GITHUB_TOKEN:
    print(f"GitHub Token å‰ç¼€: {GITHUB_TOKEN[:6]}...")

# å¸¸é‡å®šä¹‰
API_ENDPOINTS = {
    "copilot": "https://models.github.ai/inference/chat/completions",
    "openrouter": "https://openrouter.ai/api/v1/chat/completions"
}

# é€šç”¨å‡½æ•°

def make_api_request(url: str, headers: Dict, data: Dict, retries: int = RETRY_ATTEMPTS, retry_delay: int = REQUEST_RETRY_DELAY) -> Optional[Dict]:
    """é€šç”¨çš„ API è¯·æ±‚å‡½æ•°ï¼Œæ”¯æŒé‡è¯•é€»è¾‘"""
    for attempt in range(retries):
        try:
            resp = requests.post(url, headers=headers, data=json.dumps(data), timeout=REQUEST_TIMEOUT)
            if resp.status_code == 429:
                if attempt < retries - 1:
                    print(f"é‡åˆ° 429 é”™è¯¯ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{retries})")
                    time.sleep(retry_delay)
                    continue
                else:
                    raise requests.HTTPError("429 Too Many Requests")
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            if attempt < retries - 1:
                print(f"API è°ƒç”¨å¤±è´¥ï¼Œç­‰å¾… {retry_delay} ç§’åé‡è¯•: {e}")
                time.sleep(retry_delay)
                continue
            else:
                print(f"API è°ƒç”¨å¤±è´¥: {e}")
                return None


def generate_prompt(repo: Dict) -> str:
    """ç”Ÿæˆé€šç”¨çš„æ€»ç»“æç¤º"""
    repo_name = repo["full_name"]
    desc = repo.get("description") or ""
    url = repo["html_url"]
    if LANGUAGE == 'zh':
        return (
            f"è¯·å¯¹ä»¥ä¸‹ GitHub ä»“åº“è¿›è¡Œå†…å®¹æ€»ç»“ï¼ŒæŒ‰å¦‚ä¸‹æ ¼å¼è¾“å‡ºï¼š\n"
            f"1. **ä»“åº“åç§°ï¼š** {repo_name}\n"
            f"2. **ç®€è¦ä»‹ç»ï¼š** ï¼ˆ50å­—ä»¥å†…ï¼‰\n"
            f"3. **åˆ›æ–°ç‚¹ï¼š** ï¼ˆç®€è¿°æœ¬ä»“åº“æœ€æœ‰ç‰¹è‰²çš„åœ°æ–¹ï¼‰\n"
            f"4. **ç®€å•ç”¨æ³•ï¼š** ï¼ˆç»™å‡ºæœ€ç®€å…³é”®ç”¨æ³•æˆ–è°ƒç”¨ç¤ºä¾‹ï¼Œå¦‚æ— åˆ™ç•¥ï¼‰\n"
            f"5. **æ€»ç»“ï¼š** ï¼ˆä¸€å¥è¯æ€»ç»“å®ƒçš„ç”¨é€”/ä»·å€¼ï¼‰\n"
            f"**ä»“åº“æè¿°ï¼š** {desc}\n"
            f"**ä»“åº“åœ°å€ï¼š** {url}\n"
        )
    else:
        return (
            f"Please summarize the following GitHub repository in the specified format:\n"
            f"1. **Repository Name:** {repo_name}\n"
            f"2. **Brief Introduction:** (within 50 words)\n"
            f"3. **Innovations:** (Briefly describe the most distinctive features)\n"
            f"4. **Basic Usage:** (Provide the simplest key usage or example, omit if none)\n"
            f"5. **Summary:** (One sentence summarizing its purpose/value)\n"
            f"**Repository Description:** {desc}\n"
            f"**Repository URL:** {url}\n"
        )

def get_starred_repos() -> List[Dict]:
    """è·å–ç”¨æˆ·çš„ GitHub æ˜Ÿæ ‡ä»“åº“"""
    if not GITHUB_TOKEN:
        raise ValueError("ç¼ºå°‘ GITHUB_TOKEN ç¯å¢ƒå˜é‡")
    
    print("æ­£åœ¨è·å–æ˜Ÿæ ‡ä»“åº“...")
    repos = []
    page = 1
    per_page = 100
    headers = {
        "Authorization": f"Bearer {GITHUB_TOKEN}",
        "Accept": "application/vnd.github+json"
    }
    
    while True:
        try:
            url = f"https://api.github.com/users/{GITHUB_USERNAME}/starred?per_page={per_page}&page={page}"
            resp = requests.get(url, headers=headers, timeout=REQUEST_TIMEOUT)
            resp.raise_for_status()
            data = resp.json()
            
            if not data:
                break
                
            repos.extend(data)
            print(f"å·²è·å– {len(repos)} ä¸ªä»“åº“... (ç¬¬ {page} é¡µ)")
            page += 1
            
            # é¿å… GitHub API é™åˆ¶
            time.sleep(1)
            
        except requests.RequestException as e:
            print(f"è·å–æ˜Ÿæ ‡ä»“åº“å¤±è´¥: {e}")
            break
    
    print(f"æ€»å…±è·å–åˆ° {len(repos)} ä¸ªæ˜Ÿæ ‡ä»“åº“")
    return repos


def load_old_summaries():
    """è¯»å–æ—§çš„README-sum.mdï¼Œè¿”å›å­—å…¸: {repo_full_name: summary}"""
    if not os.path.exists(README_SUM_PATH):
        return {}
    summaries = {}
    current_repo = None
    current_lines = []
    with open(README_SUM_PATH, encoding="utf-8") as f:
        for line in f:
            if line.startswith("### ["):
                if current_repo and current_lines:
                    summaries[current_repo] = "".join(current_lines).strip()
                # è§£æä»“åº“å
                left = line.find('[') + 1
                right = line.find(']')
                current_repo = line[left:right]
                current_lines = []
            elif current_repo:
                current_lines.append(line)
        if current_repo and current_lines:
            summaries[current_repo] = "".join(current_lines).strip()
    return summaries


# æ–°å¢ï¼šä½¿ç”¨ GitHub Copilot / GitHub Models API è¿›è¡Œæ€»ç»“
# éœ€è¦ STARRED_GITHUB_TOKEN å…·å¤‡è®¿é—® models:read & copilot èŒƒå›´ï¼ˆä¸€èˆ¬ PAT å¯ç”¨ copilot å³å¯ï¼‰
# å¯é€šè¿‡ç¯å¢ƒå˜é‡ GITHUB_COPILOT_MODEL æŒ‡å®šæ¨¡å‹ï¼Œé»˜è®¤ gpt-4o-miniï¼ˆä¾æ® GitHub Models å¯ç”¨æ¨¡å‹è‡ªè¡Œè°ƒæ•´ï¼‰


def is_valid_summary(summary: str) -> bool:
    """æ£€æŸ¥ç»™å®šçš„æ€»ç»“æ˜¯å¦æœ‰æ•ˆï¼ˆä¸åŒ…å«ç”Ÿæˆå¤±è´¥ç­‰å†…å®¹ï¼‰"""
    invalid_phrases = ["ç”Ÿæˆå¤±è´¥", "æš‚æ— AIæ€»ç»“", "429"]
    return not any(phrase in summary for phrase in summary)


def summarize_batch(repos: List[Dict], old_summaries: Dict[str, str], use_copilot: bool = False) -> List[str]:
    """æ‰¹é‡æ€»ç»“ä»“åº“ï¼Œæ”¯æŒé€‰æ‹©ä½¿ç”¨ OpenRouter æˆ– GitHub Copilot"""
    results = [None] * len(repos)
    summarize_func = copilot_summarize if use_copilot else openrouter_summarize
    api_name = "Copilot" if use_copilot else "OpenRouter"
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_idx = {
            executor.submit(summarize_func, repo): idx
            for idx, repo in enumerate(repos)
        }
        for future in concurrent.futures.as_completed(future_to_idx):
            idx = future_to_idx[future]
            repo = repos[idx]
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆæ€»ç»“
                existing_summary = old_summaries.get(repo["full_name"], "")
                if is_valid_summary(existing_summary):
                    summary = existing_summary
                else:
                    summary = future.result()
                    if summary is None:  # 429ç­‰å¤±è´¥
                        summary = old_summaries.get(repo["full_name"], f"{api_name} APIç”Ÿæˆå¤±è´¥æˆ–429")
            except Exception as exc:
                print(f"{repo['full_name']} çº¿ç¨‹å¼‚å¸¸: {exc}")
                summary = old_summaries.get(repo["full_name"], f"{api_name} APIç”Ÿæˆå¤±è´¥")
            results[idx] = summary
    return results


def copilot_summarize_batch(repos: List[Dict], old_summaries: Dict[str, str]) -> List[str]:
    """ä½¿ç”¨ GitHub Copilot æ‰¹é‡æ€»ç»“ä»“åº“"""
    return summarize_batch(repos, old_summaries, use_copilot=True)


def classify_by_language(repos):
    classified = {}
    for repo in repos:
        lang = repo.get("language") or "Other"
        classified.setdefault(lang, []).append(repo)
    return classified


def update_existing_summaries(lines, old_summaries):
    """æ›´æ–°å·²æœ‰çš„ README-sum.md æ–‡ä»¶ä¸­çš„æ€»ç»“å†…å®¹"""
    updated_lines = []
    current_repo = None
    for line in lines:
        if line.startswith("### ["):
            # è§£æä»“åº“å
            left = line.find('[') + 1
            right = line.find(']')
            current_repo = line[left:right]
            updated_lines.append(line)
        elif current_repo and current_repo in old_summaries:
            # æ›¿æ¢ä¸ºæ–°çš„æ€»ç»“å†…å®¹
            updated_lines.append(old_summaries[current_repo] + "\n")
            current_repo = None  # é‡ç½®å½“å‰ä»“åº“
        else:
            updated_lines.append(line)
    return updated_lines

###########################################
def main():
    # é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ä½¿ç”¨å“ªç§ APIï¼Œé»˜è®¤ä½¿ç”¨ Copilot
    use_copilot_api = os.environ.get("USE_COPILOT_API", "true").lower() == "true"
    api_name = "GitHub Copilot" if use_copilot_api else "OpenRouter (DeepSeek)"
    
    print(f"å¼€å§‹ä½¿ç”¨ {api_name} ç”Ÿæˆ GitHub Star é¡¹ç›®æ€»ç»“...")
    
    try:
        starred = get_starred_repos()
        classified = classify_by_language(starred)
        old_summaries = load_old_summaries()
        
        # æ›´æ–°æ ‡é¢˜ä»¥åæ˜ å®é™…ä½¿ç”¨çš„ API
        current_time = time.strftime("%Yå¹´%mæœˆ%dæ—¥", time.localtime())
        title = f"# æˆ‘çš„ GitHub Star é¡¹ç›®AIæ€»ç»“\n\n"
        title += f"**ç”Ÿæˆæ—¶é—´ï¼š** {current_time}\n\n"
        title += f"**AIæ¨¡å‹ï¼š** {api_name}\n\n"
        title += f"**æ€»ä»“åº“æ•°ï¼š** {len(starred)} ä¸ª\n\n"
        title += "---\n\n"
        
        lines = [title]
        
        # æ·»åŠ ç›®å½•
        lines.append("## ğŸ“– ç›®å½•\n\n")
        lang_counts = {}
        for lang, repos in classified.items():
            lang_counts[lang] = len(repos)
        
        for lang, count in sorted(lang_counts.items(), key=lambda x: -x[1]):
            lines.append(f"- [{lang}](#-{lang.lower().replace(' ', '-').replace('+', 'plus').replace('#', 'sharp')})ï¼ˆ{count}ä¸ªï¼‰\n")
        lines.append("\n---\n\n")
        
        printed_repos = set()
        printed_langs = set()  # è®°å½•å·²è¾“å‡ºçš„è¯­è¨€
        
        total_repos = sum(len(repos) for repos in classified.values())
        processed_repos = 0
        
        for lang, repos in sorted(classified.items(), key=lambda x: -len(x[1])):
            if lang in printed_langs:
                continue  # è·³è¿‡å·²è¾“å‡ºçš„è¯­è¨€æ ‡é¢˜
            printed_langs.add(lang)
            print(f"æ­£åœ¨å¤„ç† {lang} ç±»å‹çš„ä»“åº“ï¼ˆå…±{len(repos)}ä¸ªï¼‰...")
            
            # æ·»åŠ è¯­è¨€æ ‡é¢˜å’Œå›¾æ ‡
            lang_icon = {
                "Python": "ğŸ", "JavaScript": "ğŸŸ¨", "TypeScript": "ğŸ”·", 
                "Java": "â˜•", "Go": "ğŸ¹", "Rust": "ğŸ¦€", "C++": "âš¡", 
                "C": "ğŸ”§", "C#": "ğŸ’œ", "PHP": "ğŸ˜", "Ruby": "ğŸ’", 
                "Swift": "ğŸ¦", "Kotlin": "ğŸ…º", "Dart": "ğŸ¯", 
                "Shell": "ğŸš", "HTML": "ğŸŒ", "CSS": "ğŸ¨", 
                "Vue": "ğŸ’š", "React": "âš›ï¸", "Other": "ğŸ“¦"
            }.get(lang, "ğŸ“")
            
            lines.append(f"## {lang_icon} {lang}ï¼ˆå…±{len(repos)}ä¸ªï¼‰\n\n")
            
            for i in range(0, len(repos), BATCH_SIZE):
                this_batch = repos[i:i+BATCH_SIZE]
                print(f"å¤„ç†æ‰¹æ¬¡ {i//BATCH_SIZE + 1}ï¼ŒåŒ…å« {len(this_batch)} ä¸ªä»“åº“...")
                
                # æ ¹æ®é€‰æ‹©ä½¿ç”¨ä¸åŒçš„æ€»ç»“å‡½æ•°
                if use_copilot_api:
                    summaries = copilot_summarize_batch(this_batch, old_summaries)
                else:
                    summaries = summarize_batch(this_batch, old_summaries, use_copilot=False)
                
                for repo, summary in zip(this_batch, summaries):
                    if repo['full_name'] in printed_repos:
                        continue  # è·³è¿‡å·²è¾“å‡ºçš„ä»“åº“
                    printed_repos.add(repo['full_name'])
                    
                    # è·å–ä»“åº“ä¿¡æ¯
                    url = repo["html_url"]
                    stars = repo.get("stargazers_count", 0)
                    forks = repo.get("forks_count", 0)
                    language = repo.get("language", "Unknown")
                    updated_at = repo.get("updated_at", "")
                    if updated_at:
                        try:
                            # è§£ææ—¶é—´å¹¶æ ¼å¼åŒ–
                            from datetime import datetime
                            dt = datetime.fromisoformat(updated_at.replace('Z', '+00:00'))
                            updated_at = dt.strftime("%Y-%m-%d")
                        except:
                            updated_at = updated_at[:10]  # å–å‰10ä¸ªå­—ç¬¦ä½œä¸ºæ—¥æœŸ
                    
                    # æ„å»ºä»“åº“æ¡ç›®
                    lines.append(f"### ğŸ“Œ [{repo['full_name']}]({url})\n\n")
                    
                    # æ·»åŠ ä»“åº“å…ƒä¿¡æ¯
                    lines.append(f"**â­ Stars:** {stars:,} | **ğŸ´ Forks:** {forks:,} | **ğŸ“… æ›´æ–°:** {updated_at}\n\n")
                    
                    # æ·»åŠ AIæ€»ç»“å†…å®¹
                    if summary and summary.strip():
                        lines.append(f"{summary}\n\n")
                    else:
                        lines.append("*æš‚æ— AIæ€»ç»“*\n\n")
                    
                    lines.append("---\n\n")
                    processed_repos += 1
                
                print(f"å·²å¤„ç† {processed_repos}/{total_repos} ä¸ªä»“åº“")
                time.sleep(RATE_LIMIT_DELAY)  # é¿å… API é™æµ
        
        # æ·»åŠ é¡µè„š
        lines.append(f"\n## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯\n\n")
        lines.append(f"- **æ€»ä»“åº“æ•°ï¼š** {processed_repos} ä¸ª\n")
        lines.append(f"- **ç¼–ç¨‹è¯­è¨€æ•°ï¼š** {len(classified)} ç§\n")
        lines.append(f"- **ç”Ÿæˆæ—¶é—´ï¼š** {current_time}\n")
        lines.append(f"- **AIæ¨¡å‹ï¼š** {api_name}\n\n")
        lines.append("---\n\n")
        lines.append("*æœ¬æ–‡æ¡£ç”±AIè‡ªåŠ¨ç”Ÿæˆï¼Œå¦‚æœ‰é”™è¯¯è¯·ä»¥åŸä»“åº“ä¿¡æ¯ä¸ºå‡†ã€‚*\n")
        
        # å†™å…¥æ–‡ä»¶
        if os.path.exists(README_SUM_PATH):
            with open(README_SUM_PATH, "r", encoding="utf-8") as f:
                existing_lines = f.readlines()
            updated_lines = update_existing_summaries(existing_lines, {repo['full_name']: summary for repo, summary in zip(this_batch, summaries)})
            with open(README_SUM_PATH, "w", encoding="utf-8") as f:
                f.writelines(updated_lines)
        else:
            with open(README_SUM_PATH, "w", encoding="utf-8") as f:
                f.write(''.join(lines))
        
        print(f"\nâœ… {README_SUM_PATH} å·²ç”Ÿæˆï¼Œå…±å¤„ç†äº† {processed_repos} ä¸ªä»“åº“ã€‚")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()